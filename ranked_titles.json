[
    {
        "sentence": "A Novel LLM Architecture for Intelligent System Configuration",
        "score": "7.7058296"
    },
    {
        "sentence": "LCM: LLM-focused Hybrid SPM-cache Architecture with Cache Management for Multi-Core AI Accelerators",
        "score": "7.282982"
    },
    {
        "sentence": "BlockLLM: A futuristic LLM-based decentralized vehicular network architecture for secure communications",
        "score": "6.677014"
    },
    {
        "sentence": "RetailGPT: A Fine-Tuned LLM Architecture for Customer Experience and Sales Optimization",
        "score": "6.398651"
    },
    {
        "sentence": "Cambricon-LLM: A Chiplet-Based Hybrid Architecture for On-Device Inference of 70B LLM",
        "score": "6.232016"
    },
    {
        "sentence": "NeuroShield: A Modular Immunological Architecture for Emotional LLM Systems",
        "score": "6.212877"
    },
    {
        "sentence": "LLM Guardrail Framework: A Novel Approach for\u00a0Implementing Zero Trust Architecture",
        "score": "6.021482"
    },
    {
        "sentence": "LLM-Driven Chest X-Ray Report Generation With a\u00a0Modular, Reduced-Size Architecture",
        "score": "5.838044"
    },
    {
        "sentence": "A Taxonomy for Autonomous LLM-Powered Multi-Agent Architectures",
        "score": "5.764173"
    },
    {
        "sentence": "IsolateGPT: An Execution Isolation Architecture for LLM-Based Systems",
        "score": "5.6349535"
    },
    {
        "sentence": "A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture",
        "score": "5.5675044"
    },
    {
        "sentence": "LLM as HPC Expert: Extending RAG Architecture for HPC Data",
        "score": "5.533615"
    },
    {
        "sentence": "A LLM Checkpointing System of the Hybrid Memory Architecture",
        "score": "5.477754"
    },
    {
        "sentence": "Large Language Model (LLM) for Standard Cell Layout Design Optimization",
        "score": "5.3447685"
    },
    {
        "sentence": "Ready for departure: Factors to adopt large language model (LLM)-based artificial intelligence (AI) technology in the architecture, engineering and construction (AEC) industry",
        "score": "5.323708"
    },
    {
        "sentence": "Similarity Controlled Text Generation using an Embedding Informed LLM Architecture",
        "score": "5.1302247"
    },
    {
        "sentence": "A Case Study of Hybrid-Architecture Multimodal LLM for Traditional Manufacturing Productivity Enhancement",
        "score": "5.059603"
    },
    {
        "sentence": "LLM Performance Predictors are good initializers for Architecture Search",
        "score": "4.9914336"
    },
    {
        "sentence": "15 Identifying the Optimal Architecture for Using Local Large Language Models (LLM) In Autopsy Pathology Reports",
        "score": "4.8829784"
    },
    {
        "sentence": "Helping Novice Architects to Make Quality Design Decisions Using an LLM-Based Assistant",
        "score": "4.8752217"
    },
    {
        "sentence": "Development of intelligent content moderation systems for electronic publications based on LLM and RAG architecture",
        "score": "4.784819"
    },
    {
        "sentence": "Review of: \"LLM as HPC Expert: Extending RAG Architecture for HPC Data\"",
        "score": "4.581801"
    },
    {
        "sentence": "Review of: \"LLM as HPC Expert: Extending RAG Architecture for HPC Data\"",
        "score": "4.581801"
    },
    {
        "sentence": "Academic Query Assistant: Integrating LLM API into an Academic Assistant Using a Microservices Architecture",
        "score": "4.401475"
    },
    {
        "sentence": "Analysis of the Integration Strategies of LLM and VLM Models with the Transformer Architecture",
        "score": "4.344304"
    },
    {
        "sentence": "LLM-WFIN: A Fine-Grained Large Language Model (LLM)-Oriented Website Fingerprinting Attack via Fusing Interrupt Trace and Network Traffic",
        "score": "4.1702394"
    },
    {
        "sentence": "Tokenization Offload Architecture (TOA): Reframing Client-Side Tokenization as a Foundational Layer in LLM Optimization",
        "score": "4.151102"
    },
    {
        "sentence": "A functional contextual, observer-centric, quantum mechanical, and neuro-symbolic approach to solving the alignment problem of artificial general intelligence: safe AI through intersecting computational psychological neuroscience and LLM architecture for emergent theory of mind",
        "score": "3.9945962"
    },
    {
        "sentence": "Analysis of Transformer Decoder Architecture and KV Cache Behavior During LLM Inference",
        "score": "3.969422"
    },
    {
        "sentence": "Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm",
        "score": "3.9069843"
    },
    {
        "sentence": "Generative-AI(with Custom-Trained Meta's Llama2 LLM), Blockchain, NFT, Federated Learning and PBOM Enabled Data Security Architecture for Metaverse on 5G/6G Environment",
        "score": "3.857891"
    },
    {
        "sentence": "LLM-enabled Incremental Learning Framework for Hand Exoskeleton Control",
        "score": "3.5778475"
    },
    {
        "sentence": "LLM-enabled Incremental Learning Framework for Hand Exoskeleton Control",
        "score": "3.5778475"
    },
    {
        "sentence": "An Introduction to LLM-Graph-Builder",
        "score": "3.5371122"
    },
    {
        "sentence": "Implementation and Architecture Design of a business Q&amp;A bot Combining LLM and Chatbot",
        "score": "3.406531"
    },
    {
        "sentence": "Enhancing source code retrieval with joint Bi-LSTM-GNN architecture: A comparative study with ChatGPT-LLM",
        "score": "2.9446795"
    },
    {
        "sentence": "LLM-Assisted Crisis Management: Building Advanced LLM Platforms for Effective Emergency Response and Public Collaboration",
        "score": "2.6611946"
    },
    {
        "sentence": "2024 IEEE LLM Aided Design Workshop (LAD)",
        "score": "2.5241346"
    },
    {
        "sentence": "Large Language Model (LLM) Monthly Report (2024 Apr)",
        "score": "2.4143062"
    },
    {
        "sentence": "Around meta-analysis (15): emerging Large Language Models (LLM) tools",
        "score": "2.327248"
    },
    {
        "sentence": "LLM-Aided Compilation for Tensor Accelerators",
        "score": "2.130457"
    },
    {
        "sentence": "LLM-Aided Compilation for Tensor Accelerators",
        "score": "2.130457"
    },
    {
        "sentence": "DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency",
        "score": "1.8898821"
    },
    {
        "sentence": "Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration",
        "score": "1.7936368"
    },
    {
        "sentence": "Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration",
        "score": "1.7936368"
    },
    {
        "sentence": "Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration",
        "score": "1.7936368"
    },
    {
        "sentence": "LLM-TOPLA: Efficient LLM Ensemble by Maximising Diversity",
        "score": "1.783185"
    },
    {
        "sentence": "Llm-Based Ir-System for Bank Supervisors",
        "score": "1.685019"
    },
    {
        "sentence": "Large Language Models(LLM) for Automating 20 Questions Game",
        "score": "1.6719589"
    },
    {
        "sentence": "LLM-Based Fine-Grained ABAC Policy Generation",
        "score": "1.6636388"
    },
    {
        "sentence": "LLM-AIDSim: LLM-Enhanced Agent-Based Influence Diffusion Simulation in Social Networks",
        "score": "1.659524"
    },
    {
        "sentence": "VerilogReader: LLM-Aided Hardware Test Generation",
        "score": "1.6407585"
    },
    {
        "sentence": "ECO-LLM: LLM-based Edge Cloud Optimization",
        "score": "1.538593"
    },
    {
        "sentence": "LLM as decoder: Investigating Lattice-based Speech Recognition Hypotheses Rescoring Using LLM",
        "score": "1.3953925"
    },
    {
        "sentence": "EMU-LLM: Emulators for Performance Evaluation of LLM-based Applications",
        "score": "1.206404"
    },
    {
        "sentence": "LLM-Generated Class Descriptions for Semantically Meaningful Image Classification",
        "score": "1.1373122"
    },
    {
        "sentence": "LLM-Vectorizer: LLM-Based Verified Loop Vectorizer",
        "score": "1.0763583"
    },
    {
        "sentence": "LLM-IE Base on Prompt Enhance",
        "score": "0.89680886"
    },
    {
        "sentence": "Cyber Threat Modeling of an LLM-Based Healthcare System",
        "score": "0.87875473"
    },
    {
        "sentence": "CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation",
        "score": "0.8133811"
    },
    {
        "sentence": "AlphaSharpe: LLM-Driven Discovery of Robust Risk-Adjusted Metrics",
        "score": "0.77350956"
    },
    {
        "sentence": "LLM+\u00d7IOWN --The Advancement of IOWN, the Launch of NTT\u2019s LLM, and Their Synergy--",
        "score": "0.6968918"
    },
    {
        "sentence": "Personalized NPC Based on the LLM Model Consideration of Communication Scalability",
        "score": "0.6480048"
    },
    {
        "sentence": "LLM-MHR: A LLM-Augmented Multimodal Hashtag Recommendation Algorithm",
        "score": "0.50764495"
    },
    {
        "sentence": "Ef-Llm: Energy Forecasting Llm with Ai-Assisted Automation, Enhanced Sparse Prediction, Hallucination Detection",
        "score": "0.4892831"
    },
    {
        "sentence": "Ef-Llm: Energy Forecasting Llm with Ai-Assisted Automation, Enhanced Sparse Prediction, Hallucination Detection",
        "score": "0.4892831"
    },
    {
        "sentence": "The New World of LLM Functions: Integrating LLM Technology into the Wolfram Language",
        "score": "0.45749936"
    },
    {
        "sentence": "LLM Output Compliance with Handcrafted Linguistic Features: An Experiment",
        "score": "0.3253679"
    },
    {
        "sentence": "Survey Trends using LLM Models",
        "score": "0.31044358"
    },
    {
        "sentence": "Towards LLM-Based Autograding for Short Textual Answers",
        "score": "0.2732262"
    },
    {
        "sentence": "VQ-LLM: High-performance Code Generation for Vector Quantization Augmented LLM Inference",
        "score": "0.26687732"
    },
    {
        "sentence": "PAISE: PIM-Accelerated Inference Scheduling Engine for Transformer-based LLM",
        "score": "0.24657172"
    },
    {
        "sentence": "Strengthening Llm Ecosystem Security: Preventing Mobile Malware from Manipulating Llm-Based Applications",
        "score": "0.24524312"
    },
    {
        "sentence": "Integrating LLM APIs with LangChain",
        "score": "0.15268545"
    },
    {
        "sentence": "Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots",
        "score": "0.112833634"
    },
    {
        "sentence": "A Collaborative Approach to Multimodal Machine Translation: VLM and LLM",
        "score": "-0.0066738427"
    },
    {
        "sentence": "Evaluating the Usability of an LLM-Aided Hybrid Avatar Agent System",
        "score": "-0.014388274"
    },
    {
        "sentence": "Exploring LLM Research Trends and Insights for Enhanced Accessibility",
        "score": "-0.026112337"
    },
    {
        "sentence": "In the Beginning was the Word: LLM-VaR and LLM-ES",
        "score": "-0.04015843"
    },
    {
        "sentence": "In the Beginning Was the Word: Llm-Var and Llm-Es",
        "score": "-0.04015843"
    },
    {
        "sentence": "LLM-aided explanations of EDA synthesis errors",
        "score": "-0.05359916"
    },
    {
        "sentence": "MECLA: Memory-Compute-Efficient LLM Accelerator with Scaling Sub-matrix Partition",
        "score": "-0.083361596"
    },
    {
        "sentence": "LLM-ABBA: Understanding Time Series via Symbolic Approximation",
        "score": "-0.08484611"
    },
    {
        "sentence": "Reviewing LLM Articles",
        "score": "-0.16898932"
    },
    {
        "sentence": "Religion, Theology, and Philosophical Skills of LLM\u2013Powered Chatbots",
        "score": "-0.23670605"
    },
    {
        "sentence": "Ergonomic LLM or LLM for Ergonomics? Prompt engineering insights for an interventional case study",
        "score": "-0.25072318"
    },
    {
        "sentence": "LLM See, LLM Do: Leveraging Active Inheritance to Target Non-Differentiable Objectives",
        "score": "-0.40528873"
    },
    {
        "sentence": "Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems",
        "score": "-0.4875261"
    },
    {
        "sentence": "Literature Reviews with Llm-Based Tools",
        "score": "-0.6276168"
    },
    {
        "sentence": "GPU-Centric Memory Tiering for LLM Serving With NVIDIA Grace Hopper Superchip",
        "score": "-0.65184796"
    },
    {
        "sentence": "Podej\u015bcie HELIOS. Wykorzystanie sztucznej inteligencji i du\u017cych modeli j\u0119zykowych (LLM) do ulepszonej identyfikacji jednorodno\u015bci w analizie rynku nieruchomo\u015bci",
        "score": "-0.6658189"
    },
    {
        "sentence": "BioChatter and the future of LLM driven bioscience",
        "score": "-0.67530406"
    },
    {
        "sentence": "The LLM Quant Revolution: From ChatGPT to Wall Street",
        "score": "-0.7535044"
    },
    {
        "sentence": "The LLM Quant Revolution: From ChatGPT to Wall Street",
        "score": "-0.7535044"
    },
    {
        "sentence": "Balancing Progress and Responsibility: Ethical Dimensions of LLM Development",
        "score": "-0.83896077"
    },
    {
        "sentence": "Validating Color Scheme Generation with LLM",
        "score": "-0.8722755"
    },
    {
        "sentence": "LLM generated summaries for protein classification at InterPro",
        "score": "-0.87832135"
    },
    {
        "sentence": "Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and Abbreviation De-hallucination",
        "score": "-0.8796117"
    },
    {
        "sentence": "Factored Cognition Models: Enhancing LLM Performance through Modular Decomposition",
        "score": "-0.8890249"
    },
    {
        "sentence": "Content Moderation by LLM: From Accuracy to Legitimacy",
        "score": "-0.9206144"
    },
    {
        "sentence": "Personalization and Customization of LLM Responses",
        "score": "-1.0288264"
    },
    {
        "sentence": "OASIS: Outlier-Aware KV Cache Clustering for Scaling LLM Inference in CXL Memory Systems",
        "score": "-1.1044949"
    },
    {
        "sentence": "Automatic extraction of FAIR data from publications using LLM",
        "score": "-1.1547477"
    },
    {
        "sentence": "Automatic extraction of FAIR data from publications using LLM",
        "score": "-1.1547477"
    },
    {
        "sentence": "LLM Tutors for Computer Science Courses",
        "score": "-1.1550368"
    },
    {
        "sentence": "LLM- Based Personalized Recommendations in Health",
        "score": "-1.1777521"
    },
    {
        "sentence": "LLM Based Math Tutoring: Challenges and Dataset",
        "score": "-1.1922867"
    },
    {
        "sentence": "Lincoln: Real-Time 50~100B LLM Inference on Consumer Devices with LPDDR-Interfaced, Compute-Enabled Flash Memory",
        "score": "-1.2602575"
    },
    {
        "sentence": "A Knowledge Distillation Algorithm for LLM Based on Weakness Enhancement",
        "score": "-1.3573155"
    },
    {
        "sentence": "BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment",
        "score": "-1.3720769"
    },
    {
        "sentence": "LUNG-GPT: Lung sound analysis with LLM-Based  model",
        "score": "-1.4012907"
    },
    {
        "sentence": "Adaptive Reinforcement Learning with LLM-augmented Reward Functions",
        "score": "-1.4648244"
    },
    {
        "sentence": "Adaptive Reinforcement Learning with LLM-augmented Reward Functions",
        "score": "-1.4648244"
    },
    {
        "sentence": "An Iteratively-refined Dataset for High-Level Synthesis Functional Verification through LLM-Aided Bug Injection",
        "score": "-1.4775434"
    },
    {
        "sentence": "A Survey of LLM for Data Privacy Issue and Future Direction",
        "score": "-1.5277835"
    },
    {
        "sentence": "GenAI and LLM for Financial Institutions: A Corporate Strategic Survey",
        "score": "-1.5382429"
    },
    {
        "sentence": "Program Scalability Analysis for LLM Endpoints: Ahmdal's Law Analysis of Parallelizability Benefits of LLM Completions Endpoints*",
        "score": "-1.5607256"
    },
    {
        "sentence": "Review of: \"LLM-ABBA: Understanding Time Series via Symbolic Approximation\"",
        "score": "-1.585987"
    },
    {
        "sentence": "Review of: \"LLM-ABBA: Understanding Time Series via Symbolic Approximation\"",
        "score": "-1.585987"
    },
    {
        "sentence": "RGQA: Leveraging Reasoning Guideline with LLM-based KGQA",
        "score": "-1.6325147"
    },
    {
        "sentence": "Harnessing LLM Conversations for Goal Model Generation from User Reviews",
        "score": "-1.6329813"
    },
    {
        "sentence": "Development of a Korean News Question Answering System Based on LLM Using RAPTOR",
        "score": "-1.6811805"
    },
    {
        "sentence": "Human-LLM Collaborative Annotation Through Effective Verification of LLM Labels",
        "score": "-1.7080736"
    },
    {
        "sentence": "Anda: Unlocking Efficient LLM Inference with a Variable-Length Grouped Activation Data Format",
        "score": "-1.7178118"
    },
    {
        "sentence": "BitMoD: Bit-serial Mixture-of-Datatype LLM Acceleration",
        "score": "-1.74718"
    },
    {
        "sentence": "Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM",
        "score": "-1.7655516"
    },
    {
        "sentence": "Improving LLM Accuracy in Checkable Scenarios via Scope Expansion",
        "score": "-1.7685428"
    },
    {
        "sentence": "FACIL: Flexible DRAM Address Mapping for SoC-PIM Cooperative On-device LLM Inference",
        "score": "-1.7737397"
    },
    {
        "sentence": "LLM-Pilot: Characterize and Optimize Performance of your LLM Inference Services",
        "score": "-1.7769427"
    },
    {
        "sentence": "Enhancing Annotated Bibliography Generation with LLM Ensembles",
        "score": "-1.7981523"
    },
    {
        "sentence": "LAD: Efficient Accelerator for Generative Inference of LLM with Locality Aware Decoding",
        "score": "-1.8138679"
    },
    {
        "sentence": "LLM Assessment of Social Importance by Ethnicity",
        "score": "-1.9892433"
    },
    {
        "sentence": "Turn any webpage into markdown for LLM-friendly input",
        "score": "-2.0577614"
    },
    {
        "sentence": "Developing a dataset for LLM projects",
        "score": "-2.0614576"
    },
    {
        "sentence": "LLM Survey Analysis Using Random Forest",
        "score": "-2.1298575"
    },
    {
        "sentence": "Comparative Analysis of LLM Responses to Prompts Related to Mainland China and Taiwan",
        "score": "-2.353621"
    },
    {
        "sentence": "A Comparative Study on the Performance of LDA and LLM-based Topic Models",
        "score": "-2.5230722"
    },
    {
        "sentence": "LLM Automatic Calculation of O-RADS Scores (Radiology In A Minute)",
        "score": "-2.554931"
    },
    {
        "sentence": "Review of: \"Enhancing Annotated Bibliography Generation with LLM Ensembles\"",
        "score": "-2.6129456"
    },
    {
        "sentence": "Review of: \"Enhancing Annotated Bibliography Generation with LLM Ensembles\"",
        "score": "-2.6129456"
    },
    {
        "sentence": "AI-Powered Insider Threat Detection with Behavioral Analytics with LLM",
        "score": "-2.6478481"
    },
    {
        "sentence": "Potential and Dangers of LLM-based Agents",
        "score": "-2.6643648"
    },
    {
        "sentence": "Deciphering the Enigma: A Deep Dive into Understanding and Interpreting LLM Outputs",
        "score": "-2.704358"
    },
    {
        "sentence": "Manipulating Prompts and Retrieval-Augmented Generation for LLM Service Providers",
        "score": "-2.708303"
    },
    {
        "sentence": "Fine-tuning human for LLM projects",
        "score": "-2.7086034"
    },
    {
        "sentence": "MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation",
        "score": "-2.9325063"
    },
    {
        "sentence": "Gemini-the most powerful LLM: Myth or Truth",
        "score": "-3.030943"
    },
    {
        "sentence": "Comparing Human Made and LLM Made Methods in Persona Creation",
        "score": "-3.1164525"
    },
    {
        "sentence": "Splitwise: Efficient Generative LLM Inference Using Phase Splitting",
        "score": "-3.1729255"
    },
    {
        "sentence": "Chain of Ideas: Revolutionizing Research via Novel Idea Development with LLM Agents",
        "score": "-3.2220435"
    },
    {
        "sentence": "Use R to prompt a local LLM with ollamar",
        "score": "-3.3769403"
    },
    {
        "sentence": "Use R to prompt a local LLM with ollamar",
        "score": "-3.3769403"
    },
    {
        "sentence": "Csi-LLM: A Novel Downlink Channel Prediction Method Aligned with LLM Pre-Training",
        "score": "-3.4203863"
    },
    {
        "sentence": "Csi-LLM: A Novel Downlink Channel Prediction Method Aligned with LLM Pre-Training",
        "score": "-3.4203863"
    },
    {
        "sentence": "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment",
        "score": "-3.4708118"
    },
    {
        "sentence": "Use an LLM to translate help documentation on-the-fly",
        "score": "-3.4778554"
    },
    {
        "sentence": "Use an LLM to translate help documentation on-the-fly",
        "score": "-3.4778557"
    },
    {
        "sentence": "Trends and Classification Performance in LLM Survey Data Analysis",
        "score": "-3.5193121"
    },
    {
        "sentence": "SLO-Aware GPU DVFS for Energy-Efficient LLM Inference Serving",
        "score": "-3.6399655"
    },
    {
        "sentence": "Analysing the potential solutions to LLM hallucinations in abstractive text summarisation",
        "score": "-3.7426817"
    },
    {
        "sentence": "Nondeterministic Torts: LLM Stochasticity and Tort Liability",
        "score": "-3.7715864"
    },
    {
        "sentence": "Cost-Effective Extension of DRAM-PIM for Group-Wise LLM Quantization",
        "score": "-3.8855793"
    },
    {
        "sentence": "How to use misinformation from LLM to our advantage",
        "score": "-3.9872746"
    },
    {
        "sentence": "Llm Analyst: What Stocks Do You Recommend Today",
        "score": "-4.016549"
    },
    {
        "sentence": "ShuffleInfer: Disaggregate LLM Inference for Mixed Downstream Workloads",
        "score": "-4.092419"
    },
    {
        "sentence": "throttLL\u2019eM: Predictive GPU Throttling for Energy Efficient LLM Inference Serving",
        "score": "-4.4561596"
    },
    {
        "sentence": "Episode 47: Standardizing LLM Research in Radiology- Part 1",
        "score": "-4.8743887"
    },
    {
        "sentence": "Empirical Evaluation of - LLM Performance Using K-S Test",
        "score": "-4.944238"
    },
    {
        "sentence": "Episode 48: Standardizing LLM Research in Radiology- Part 2",
        "score": "-5.0073676"
    },
    {
        "sentence": "A Multi-Expert Large Language Model Architecture for Verilog Code Generation",
        "score": "-7.301907"
    }
]